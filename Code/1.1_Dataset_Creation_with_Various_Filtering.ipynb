{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for Filtering_curves**\n",
    "(df, response_columns, filtering_scenario = [1,2,3], first_columns_to_compare = [1, 2], last_columns_to_compare = [-1, -2], tolerance=0.05, first_points_lower_limit = 0.8, last_points_upper_limit = 0.4)\n",
    "\n",
    "filtering_scenario = [1,2,3]\n",
    "1. Increase the tolerence levels\n",
    "\n",
    "2. Modify the locations of platues\n",
    "\n",
    "3. A combination of scenario 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "_FOLDER = \"data/\"\n",
    "_FOLDER_2 = \"results/\"\n",
    "_FOLDER_3 = \"datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilteringCurves(df, response_columns, filtering_scenario=[1, 2, 3],\n",
    "                    first_columns_to_compare=[1, 2], last_columns_to_compare=[-1, -2],\n",
    "                    tolerance=0.05, first_points_lower_limit=0.8, last_points_upper_limit=0.4):\n",
    "    \"\"\"\n",
    "    Filters the dataset based on specified criteria.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataset to filter.\n",
    "    response_columns (list): List of columns to apply the filtering.\n",
    "    filtering_scenario (list): Scenarios to apply [1, 2, 3].\n",
    "    first_columns_to_compare (list): Columns to compare for initial plateau.\n",
    "    last_columns_to_compare (list): Columns to compare for final plateau.\n",
    "    tolerance (float): Tolerance level for plateau comparison.\n",
    "    first_points_lower_limit (float): Lower limit for initial points plateau.\n",
    "    last_points_upper_limit (float): Upper limit for final points plateau.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    print(\"Original dataset:\", df.shape)\n",
    "\n",
    "    for i in filtering_scenario:\n",
    "        if i == 1:\n",
    "            # Ensure that all responses are less than 1\n",
    "            index_row_more_than_1 = df[df[response_columns].max(axis=1) > 1].index\n",
    "            df = df.drop(index_row_more_than_1)\n",
    "            # print(\"1st filtration (Responses less than 1): Filtered dataset:\", df.shape)\n",
    "\n",
    "        elif i == 2:\n",
    "            # Ensure that first and last points form plateaus\n",
    "            df[\"dif_first\"] = abs(df[response_columns[first_columns_to_compare[0] - 1]] -\n",
    "                                  df[response_columns[first_columns_to_compare[1] - 1]])\n",
    "            df[\"dif_last\"] = abs(df[response_columns[last_columns_to_compare[0]]] -\n",
    "                                 df[response_columns[last_columns_to_compare[1]]])\n",
    "            df = df[(df[\"dif_first\"] <= tolerance) & (df[\"dif_last\"] <= tolerance)]\n",
    "            # print(\"2nd filtration (Plateau formation): Filtered dataset:\", df.shape)\n",
    "\n",
    "        elif i == 3:\n",
    "            # Specify location of the plateaus\n",
    "            df = df[(df[response_columns[0]] > first_points_lower_limit) &\n",
    "                    (df[response_columns[-1]] < last_points_upper_limit)]\n",
    "            # print(\"3rd filtration (Plateau location): Filtered dataset:\", df.shape)\n",
    "\n",
    "        else:\n",
    "            print(\"Unknown filtration scenario\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asad\\AppData\\Local\\Temp\\ipykernel_12940\\2038199890.py:1: DtypeWarning: Columns (28,30,31,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  drug_curves = pd.read_csv(_FOLDER+\"normalised_dose_response_data.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225384, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_curves = pd.read_csv(_FOLDER+\"normalised_dose_response_data.csv\")\n",
    "conc_columns= [\"fd_num_\"+str(i) for i in range(10)]\n",
    "response_norm = ['norm_cells_'+str(i) for i in range(10)]\n",
    "\n",
    "drug_curves.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtration Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (225384, 44)\n",
      "Tolerance used: 0.06, Dataset size after filtering: 3667 rows\n",
      "Original dataset: (225384, 44)\n",
      "Tolerance used: 0.07, Dataset size after filtering: 4543 rows\n",
      "Original dataset: (225384, 44)\n",
      "Tolerance used: 0.08, Dataset size after filtering: 5436 rows\n",
      "Original dataset: (225384, 44)\n",
      "Tolerance used: 0.09, Dataset size after filtering: 6308 rows\n",
      "Original dataset: (225384, 44)\n",
      "Tolerance used: 0.1, Dataset size after filtering: 7145 rows\n"
     ]
    }
   ],
   "source": [
    "tolerance_values = [0.06, 0.07, 0.08, 0.09, 0.10]\n",
    "for i, tolerance in enumerate(tolerance_values, start=1):\n",
    "    filtered_df = FilteringCurves(drug_curves, response_norm, filtering_scenario=[1, 2, 3],\n",
    "                                  first_columns_to_compare=[1, 2], last_columns_to_compare=[-1, -2],\n",
    "                                  tolerance=tolerance, first_points_lower_limit=0.8, last_points_upper_limit=0.4)\n",
    "    \n",
    "    # Construct the filename\n",
    "    filename = _FOLDER_3 + 'filtering_scenario_1.' + str(i) + '.csv'\n",
    "\n",
    "    # Save the filtered dataframe\n",
    "    filtered_df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Print the size of the dataset after filtering\n",
    "    print(f\"Tolerance used: {tolerance}, Dataset size after filtering: {filtered_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (225384, 44)\n",
      "First point lower limit: 0.75, Last point upper limit: 0.45, Dataset size: 2956 rows\n",
      "Original dataset: (225384, 44)\n",
      "First point lower limit: 0.7, Last point upper limit: 0.5, Dataset size: 3125 rows\n",
      "Original dataset: (225384, 44)\n",
      "First point lower limit: 0.65, Last point upper limit: 0.55, Dataset size: 3276 rows\n"
     ]
    }
   ],
   "source": [
    "# Define ranges for first_points_lower_limit and last_points_upper_limit adjustments\n",
    "first_points_lower_limits = [0.75, 0.7, 0.65]\n",
    "last_points_upper_limits = [0.45, 0.5, 0.55]\n",
    "\n",
    "for i, (first_limit, last_limit) in enumerate(zip(first_points_lower_limits, last_points_upper_limits), start=1):\n",
    "    filtered_df = FilteringCurves(drug_curves, response_norm, filtering_scenario=[1, 2, 3],\n",
    "                                  first_columns_to_compare=[1, 2], last_columns_to_compare=[-1, -2],\n",
    "                                  tolerance=0.05, first_points_lower_limit=first_limit, last_points_upper_limit=last_limit)\n",
    "    \n",
    "    # Construct the filename for saving\n",
    "    filename = _FOLDER_3 + 'filtering_scenario_2.' + str(i) + '.csv'\n",
    "    \n",
    "    # Save the filtered dataframe\n",
    "    filtered_df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Print the size of the dataset after filtering\n",
    "    print(f\"First point lower limit: {first_limit}, Last point upper limit: {last_limit}, Dataset size: {filtered_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (225384, 44)\n",
      "Scenario 1: Tolerance: 0.06, First point lower limit: 0.75, Last point upper limit: 0.45, Dataset size: 3902 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 2: Tolerance: 0.06, First point lower limit: 0.7, Last point upper limit: 0.5, Dataset size: 4144 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 3: Tolerance: 0.06, First point lower limit: 0.65, Last point upper limit: 0.55, Dataset size: 4356 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 4: Tolerance: 0.07, First point lower limit: 0.75, Last point upper limit: 0.45, Dataset size: 4848 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 5: Tolerance: 0.07, First point lower limit: 0.7, Last point upper limit: 0.5, Dataset size: 5153 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 6: Tolerance: 0.07, First point lower limit: 0.65, Last point upper limit: 0.55, Dataset size: 5436 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 7: Tolerance: 0.08, First point lower limit: 0.75, Last point upper limit: 0.45, Dataset size: 5788 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 8: Tolerance: 0.08, First point lower limit: 0.7, Last point upper limit: 0.5, Dataset size: 6171 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 9: Tolerance: 0.08, First point lower limit: 0.65, Last point upper limit: 0.55, Dataset size: 6534 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 10: Tolerance: 0.09, First point lower limit: 0.75, Last point upper limit: 0.45, Dataset size: 6733 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 11: Tolerance: 0.09, First point lower limit: 0.7, Last point upper limit: 0.5, Dataset size: 7196 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 12: Tolerance: 0.09, First point lower limit: 0.65, Last point upper limit: 0.55, Dataset size: 7645 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 13: Tolerance: 0.1, First point lower limit: 0.75, Last point upper limit: 0.45, Dataset size: 7655 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 14: Tolerance: 0.1, First point lower limit: 0.7, Last point upper limit: 0.5, Dataset size: 8194 rows\n",
      "Original dataset: (225384, 44)\n",
      "Scenario 15: Tolerance: 0.1, First point lower limit: 0.65, Last point upper limit: 0.55, Dataset size: 8747 rows\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the parameter ranges for the third scenario\n",
    "tolerance_values = [0.06, 0.07, 0.08, 0.09, 0.10]\n",
    "first_points_lower_limits = [0.75, 0.7, 0.65]\n",
    "last_points_upper_limits = [0.45, 0.5, 0.55]\n",
    "\n",
    "# Loop through each combination of tolerance, first point lower limit, and last point upper limit\n",
    "scenario_counter = 1\n",
    "for tolerance in tolerance_values:\n",
    "    for first_limit, last_limit in zip(first_points_lower_limits, last_points_upper_limits):\n",
    "        filtered_df = FilteringCurves(drug_curves, response_norm, filtering_scenario=[1, 2, 3],\n",
    "                                      first_columns_to_compare=[1, 2], last_columns_to_compare=[-1, -2],\n",
    "                                      tolerance=tolerance, first_points_lower_limit=first_limit, last_points_upper_limit=last_limit)\n",
    "        \n",
    "        # Construct the filename for saving\n",
    "        filename = _FOLDER_3 + f'filtering_scenario_3.{scenario_counter}.csv'\n",
    "        \n",
    "        # Save the filtered dataframe\n",
    "        filtered_df.to_csv(filename, index=False)\n",
    "        \n",
    "        # Print the size of the dataset after filtering and the criteria used\n",
    "        print(f\"Scenario {scenario_counter}: Tolerance: {tolerance}, First point lower limit: {first_limit}, Last point upper limit: {last_limit}, Dataset size: {filtered_df.shape[0]} rows\")\n",
    "        \n",
    "        scenario_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
