{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train and test sets for further modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. take the drugs which have more than 10 drug profiles\n",
    "2. split them into two data sets with equal portion of each of the drugs\n",
    "3. reproduce the principle of data splitting for the case of restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "_FOLDER = \"fitted_datasets_drug_properties/\"\n",
    "_FOLDER_2 = \"test_train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test data with more than 10 record per drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing merged_fitted_drug_properties_1.1.csv.csv, shape: (3464, 1382)\n",
      "Number of drugs with more than 10 profiles: 78\n",
      "Processing merged_fitted_drug_properties_1.2.csv.csv, shape: (4292, 1382)\n",
      "Number of drugs with more than 10 profiles: 86\n",
      "Processing merged_fitted_drug_properties_1.3.csv.csv, shape: (5141, 1382)\n",
      "Number of drugs with more than 10 profiles: 91\n",
      "Processing merged_fitted_drug_properties_1.4.csv.csv, shape: (5979, 1382)\n",
      "Number of drugs with more than 10 profiles: 98\n",
      "Processing merged_fitted_drug_properties_1.5.csv.csv, shape: (6766, 1382)\n",
      "Number of drugs with more than 10 profiles: 104\n",
      "Processing merged_fitted_drug_properties_2.1.csv.csv, shape: (2781, 1382)\n",
      "Number of drugs with more than 10 profiles: 72\n",
      "Processing merged_fitted_drug_properties_2.2.csv.csv, shape: (2944, 1382)\n",
      "Number of drugs with more than 10 profiles: 74\n",
      "Processing merged_fitted_drug_properties_2.3.csv.csv, shape: (3082, 1382)\n",
      "Number of drugs with more than 10 profiles: 79\n",
      "Processing merged_fitted_drug_properties_3.1.csv.csv, shape: (3684, 1382)\n",
      "Number of drugs with more than 10 profiles: 81\n",
      "Processing merged_fitted_drug_properties_3.10.csv.csv, shape: (6374, 1382)\n",
      "Number of drugs with more than 10 profiles: 100\n",
      "Processing merged_fitted_drug_properties_3.11.csv.csv, shape: (6816, 1382)\n",
      "Number of drugs with more than 10 profiles: 106\n",
      "Processing merged_fitted_drug_properties_3.12.csv.csv, shape: (7234, 1382)\n",
      "Number of drugs with more than 10 profiles: 113\n",
      "Processing merged_fitted_drug_properties_3.13.csv.csv, shape: (7242, 1382)\n",
      "Number of drugs with more than 10 profiles: 109\n",
      "Processing merged_fitted_drug_properties_3.14.csv.csv, shape: (7757, 1382)\n",
      "Number of drugs with more than 10 profiles: 114\n",
      "Processing merged_fitted_drug_properties_3.15.csv.csv, shape: (8273, 1382)\n",
      "Number of drugs with more than 10 profiles: 120\n",
      "Processing merged_fitted_drug_properties_3.2.csv.csv, shape: (3915, 1382)\n",
      "Number of drugs with more than 10 profiles: 87\n",
      "Processing merged_fitted_drug_properties_3.3.csv.csv, shape: (4109, 1382)\n",
      "Number of drugs with more than 10 profiles: 95\n",
      "Processing merged_fitted_drug_properties_3.4.csv.csv, shape: (4575, 1382)\n",
      "Number of drugs with more than 10 profiles: 89\n",
      "Processing merged_fitted_drug_properties_3.5.csv.csv, shape: (4867, 1382)\n",
      "Number of drugs with more than 10 profiles: 96\n",
      "Processing merged_fitted_drug_properties_3.6.csv.csv, shape: (5129, 1382)\n",
      "Number of drugs with more than 10 profiles: 98\n",
      "Processing merged_fitted_drug_properties_3.7.csv.csv, shape: (5468, 1382)\n",
      "Number of drugs with more than 10 profiles: 95\n",
      "Processing merged_fitted_drug_properties_3.8.csv.csv, shape: (5834, 1382)\n",
      "Number of drugs with more than 10 profiles: 102\n",
      "Processing merged_fitted_drug_properties_3.9.csv.csv, shape: (6168, 1382)\n",
      "Number of drugs with more than 10 profiles: 105\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Define the ratio of the train set to the total data\n",
    "train_ratio = 0.8\n",
    "\n",
    "columns_to_drop = ['H', 'Target', 'Target_Pathway', 'elements']\n",
    "\n",
    "for file in os.listdir(_FOLDER):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(_FOLDER, file))\n",
    "        df = df.drop([col for col in columns_to_drop if col in df.columns], axis=1)\n",
    "\n",
    "        print(f\"Processing {file}, shape: {df.shape}\")\n",
    "        \n",
    "\n",
    "        # Group by 'DRUG_ID' and filter out those with less than 10 profiles\n",
    "        gr = df.groupby(\"DRUG_ID\").size()\n",
    "        drugs = gr[gr > 10].index\n",
    "        print(\"Number of drugs with more than 10 profiles:\", len(drugs))\n",
    "\n",
    "        train = pd.DataFrame()\n",
    "        test = pd.DataFrame()\n",
    "\n",
    "        for drug_id in drugs:\n",
    "            df_i = df[df[\"DRUG_ID\"] == drug_id]\n",
    "            indexes = np.random.permutation(df_i.index)\n",
    "            train_size = int(df_i.shape[0] * train_ratio)\n",
    "            indexes_train = indexes[:train_size]\n",
    "            indexes_test = indexes[train_size:]\n",
    "            train = pd.concat([train, df_i.loc[indexes_train, :]])\n",
    "            test = pd.concat([test, df_i.loc[indexes_test, :]])\n",
    "\n",
    "        # Save the train and test sets\n",
    "        scenario_num = file.split(\"_\")[4]  # Adjust the split index if needed\n",
    "        train.to_csv(os.path.join(_FOLDER_2, f\"train_{scenario_num}\"), index=False)\n",
    "        test.to_csv(os.path.join(_FOLDER_2, f\"test_{scenario_num}\"), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_4_param(x, x0, L, k, d):\n",
    "    \"\"\" Comparing with Dennis Wang's sigmoid:\n",
    "    x0 -  p - position, correlation with IC50 or EC50\n",
    "        bounds [0, 1]\n",
    "    L = 1 in Dennis Wang's sigmoid, protect from devision by zero if x is too small \n",
    "        L<1 inverted sigmoid, l=100 - lower upper and lower boundso sigmpoid on y axis (y= [0.1, 0.11])\n",
    "        bounds [0.8, 10]\n",
    "    k = -1/s (s -shape parameter)  default = -10 k=0 straight line, k<0 sigmoid around k=-10\n",
    "        bounds [1, -100]\n",
    "    d - determines the vertical position of the sigmoid - shift on y axis - better fitting then Dennis Wang's sigmoid\n",
    "         bounds [0, 0.9]\n",
    "    parameters_bound ((0, 0.8, -100, 0), (1, 10, 1, 0.9))\n",
    "    \"\"\"\n",
    "    return ( 1/ (L + np.exp(-k*(x-x0))) + d)\n",
    "\n",
    "def r2_score_sigmoid_4_param(df, x_columns, y_columns, param_columns = []):\n",
    "    r2_scores=np.zeros(len(df.index))\n",
    "    for i in range(len(df.index)):\n",
    "        x = df.loc[df.index[i], x_columns].values.astype(np.float32)\n",
    "        y = df.loc[df.index[i], y_columns].values.astype(np.float32)\n",
    "        fit_param = df.loc[df.index[i], param_columns].values.astype(np.float32)\n",
    "#         print(fit_param)\n",
    "        y_fit = sigmoid_4_param(x, *fit_param)\n",
    "        r2_scores[i] = r2_score(y, y_fit)\n",
    "    return r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(_FOLDER):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(_FOLDER, file))\n",
    "        \n",
    "        # Calculate R^2 scores for each row in the dataset\n",
    "        df[\"r2_scores\"] = r2_score_sigmoid_4_param(df, \n",
    "                                                   x_columns=[\"fd_num_\"+str(i) for i in range(10)],\n",
    "                                                   y_columns=[\"norm_cells_\" + str(i) for i in range(10)],\n",
    "                                                   param_columns=[\"param_\" + str(i) for i in range(1,5)])\n",
    "        \n",
    "        # Apply R^2 restriction\n",
    "        df2 = df[df[\"r2_scores\"] > 0.9].copy()\n",
    "        \n",
    "        # Group by 'DRUG_ID' and filter out those with less than a certain number of profiles\n",
    "        gr = df2.groupby(\"DRUG_ID\").size()\n",
    "        drugs = gr[gr > 10].index\n",
    "        \n",
    "        train = pd.DataFrame()\n",
    "        test = pd.DataFrame()\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        for drug_id in drugs:\n",
    "            df_i = df2[df2[\"DRUG_ID\"] == drug_id]\n",
    "            indexes = np.random.permutation(df_i.index)\n",
    "            train_size = int(len(indexes) * train_ratio)\n",
    "            indexes_train = indexes[:train_size]\n",
    "            indexes_test = indexes[train_size:]\n",
    "            train = pd.concat([train, df_i.loc[indexes_train, :]])\n",
    "            test = pd.concat([test, df_i.loc[indexes_test, :]])\n",
    "\n",
    "\n",
    "        # Save the train and test sets\n",
    "        scenario_num = file.split(\"_\")[4]  # Adjust the split index if needed\n",
    "        train.to_csv(os.path.join(_FOLDER_2, f\"train_restr_{scenario_num}\"), index=False)\n",
    "        test.to_csv(os.path.join(_FOLDER_2, f\"test_restr_{scenario_num}\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restrictions for coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(_FOLDER):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(_FOLDER, file))\n",
    "        \n",
    "        # Apply restrictions for coefficients\n",
    "        df3 = df[(df[\"param_1\"] < 1) & (df[\"param_2\"] > -5) & (df[\"param_3\"] > -120) & (df[\"param_4\"] > 0)].copy()\n",
    "\n",
    "        # Group by 'DRUG_ID' and filter out those with less than a certain number of profiles\n",
    "        gr = df3.groupby(\"DRUG_ID\").size()\n",
    "        drugs = gr[gr > 10].index\n",
    "\n",
    "        train = pd.DataFrame()\n",
    "        test = pd.DataFrame()\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        for drug_id in drugs:\n",
    "            df_i = df3[df3[\"DRUG_ID\"] == drug_id]\n",
    "            indexes = np.random.permutation(df_i.index)\n",
    "            train_size = int(len(indexes) * train_ratio)\n",
    "            indexes_train = indexes[:train_size]\n",
    "            indexes_test = indexes[train_size:]\n",
    "            train = pd.concat([train, df_i.loc[indexes_train, :]])\n",
    "            test = pd.concat([test, df_i.loc[indexes_test, :]])\n",
    "\n",
    "        \n",
    "        # Save the train and test sets\n",
    "        scenario_num = file.split(\"_\")[4]  # Adjust the split index if needed\n",
    "        train.to_csv(os.path.join(_FOLDER_2, f\"train_restr_coef_{scenario_num}\"), index=False)\n",
    "        test.to_csv(os.path.join(_FOLDER_2, f\"test_restr_coef_{scenario_num}\"), index=False)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
